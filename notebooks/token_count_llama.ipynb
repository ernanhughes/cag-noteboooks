{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count number of tokens in a file\n",
    "\n",
    "In this notebooks we are downloading models from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92512fd370445d08ea80c3b729c35d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the model\n",
    "To use this model you will need to accept the license terms from meta on your hf account.\n",
    "Note: this will take a long time and use up a lot of space on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\huggingface_models\\hub\\models--meta-llama--Meta-Llama-3-8B\\snapshots\\8cde5ca8380496c9a6cc7ef3a8b46a0372a1d920\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\projects\\cag-noteboooks\\notebooks\\shakespeare.txt\n",
      "Number of tokens in the file d:\\projects\\cag-noteboooks\\notebooks\\shakespeare.txt: 1,471,794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def get_text_from_file(file_path):\n",
    "  \"\"\"\n",
    "  Reads the entire contents of a text file.\n",
    "\n",
    "  Args:\n",
    "    file_path: The path to the text file.\n",
    "\n",
    "  Returns:\n",
    "    The contents of the file as a single string.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open(file_path, 'r') as file:\n",
    "      text_data = file.read()\n",
    "    return text_data\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: File not found at '{file_path}'\")\n",
    "    return None\n",
    "\n",
    "def get_token_count(text, model_name=\"meta-llama/Meta-Llama-3-8B\"):\n",
    "  \"\"\"\n",
    "  Calculates the number of tokens in the given text for a specified LLaMA model.\n",
    "\n",
    "  Args:\n",
    "    text: The input text string.\n",
    "    model_name: The name of the LLaMA model (default: \"meta-llama/Meta-Llama-3-8B\").\n",
    "\n",
    "  Returns:\n",
    "    The number of tokens in the text.\n",
    "  \"\"\"\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  tokens = tokenizer.encode(text)\n",
    "  return len(tokens)\n",
    "\n",
    "data_path = os.path.abspath(\"shakespeare.txt\")\n",
    "print(data_path)\n",
    "\n",
    "# Example usage\n",
    "text_data = get_text_from_file(data_path)\n",
    "token_count = get_token_count(text_data)\n",
    "print(f'Number of tokens in the file {data_path}: {\"{:,}\".format(token_count)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
